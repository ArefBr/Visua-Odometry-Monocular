{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c1e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from lib.visualization import plotting\n",
    "from lib.visualization.video import play_trip\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32165156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOdometry():\n",
    "    def __init__(self, data_dir):\n",
    "        self.K, self.P = self._load_calib(os.path.join(data_dir, 'calib.txt'))\n",
    "        self.gt_poses = self._load_poses(os.path.join(data_dir,\"poses.txt\"))\n",
    "        self.images = self._load_images(os.path.join(data_dir,\"image_l\"))\n",
    "        self.orb = cv2.ORB_create(3000)\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_calib(filepath):\n",
    "        \"\"\"\n",
    "        Loads the calibration of the camera\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to the camera file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K (ndarray): Intrinsic parameters\n",
    "        P (ndarray): Projection matrix\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P = np.reshape(params, (3, 4))\n",
    "            K = P[0:3, 0:3]\n",
    "        return K, P\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_poses(filepath):\n",
    "        \"\"\"\n",
    "        Loads the GT poses\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to the poses file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        poses (ndarray): The GT poses\n",
    "        \"\"\"\n",
    "        poses = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T = np.fromstring(line, dtype=np.float64, sep=' ')\n",
    "                T = T.reshape(3, 4)\n",
    "                T = np.vstack((T, [0, 0, 0, 1]))\n",
    "                poses.append(T)\n",
    "        return poses\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_images(filepath):\n",
    "        \"\"\"\n",
    "        Loads the images\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to image dir\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        images (list): grayscale images\n",
    "        \"\"\"\n",
    "        image_paths = [os.path.join(filepath, file) for file in sorted(os.listdir(filepath))]\n",
    "        return [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in image_paths]\n",
    "\n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "        \"\"\"\n",
    "        Makes a transformation matrix from the given rotation matrix and translation vector\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        R (ndarray): The rotation matrix\n",
    "        t (list): The translation vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        T (ndarray): The transformation matrix\n",
    "        \"\"\"\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "\n",
    "    def get_matches(self, i):\n",
    "        \"\"\"\n",
    "        This function detect and compute keypoints and descriptors from the i-1'th and i'th image using the class orb object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        i (int): The current frame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        q1 (ndarray): The good keypoints matches position in i-1'th image\n",
    "        q2 (ndarray): The good keypoints matches position in i'th image\n",
    "        \"\"\"\n",
    "        # Find the keypoints and descriptors with ORB\n",
    "        kp1, des1 = self.orb.detectAndCompute(self.images[i - 1], None)\n",
    "        kp2, des2 = self.orb.detectAndCompute(self.images[i], None)\n",
    "        # Find matches\n",
    "        matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Find the matches there do not have a to high distance\n",
    "        good = []\n",
    "        try:\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.8 * n.distance:\n",
    "                    good.append(m)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        draw_params = dict(matchColor = -1, # draw matches in green color\n",
    "                 singlePointColor = None,\n",
    "                 matchesMask = None, # draw only inliers\n",
    "                 flags = 2)\n",
    "\n",
    "        img3 = cv2.drawMatches(self.images[i], kp1, self.images[i-1],kp2, good ,None,**draw_params)\n",
    "        cv2.imshow(\"image\", img3)\n",
    "        cv2.waitKey(200)\n",
    "\n",
    "        # Get the image points form the good matches\n",
    "        q1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        q2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "        return q1, q2\n",
    "\n",
    "    def get_pose(self, q1, q2):\n",
    "        \"\"\"\n",
    "        Calculates the transformation matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q1 (ndarray): The good keypoints matches position in i-1'th image\n",
    "        q2 (ndarray): The good keypoints matches position in i'th image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformation_matrix (ndarray): The transformation matrix\n",
    "        \"\"\"\n",
    "        # Essential matrix\n",
    "        E, _ = cv2.findEssentialMat(q1, q2, self.K, threshold=1)\n",
    "\n",
    "        # Decompose the Essential matrix into R and t\n",
    "        R, t = self.decomp_essential_mat(E, q1, q2)\n",
    "\n",
    "        # Get transformation matrix\n",
    "        transformation_matrix = self._form_transf(R, np.squeeze(t))\n",
    "        return transformation_matrix\n",
    "\n",
    "    def decomp_essential_mat(self, E, q1, q2):\n",
    "        \"\"\"\n",
    "        Decompose the Essential matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        E (ndarray): Essential matrix\n",
    "        q1 (ndarray): The good keypoints matches position in i-1'th image\n",
    "        q2 (ndarray): The good keypoints matches position in i'th image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        right_pair (list): Contains the rotation matrix and translation vector\n",
    "        \"\"\"\n",
    "        def sum_z_cal_relative_scale(R, t):\n",
    "            # Get the transformation matrix\n",
    "            T = self._form_transf(R, t)\n",
    "            # Make the projection matrix\n",
    "            P = np.matmul(np.concatenate((self.K, np.zeros((3, 1))), axis=1), T)\n",
    "\n",
    "            # Triangulate the 3D points\n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            # Also seen from cam 2\n",
    "            hom_Q2 = np.matmul(T, hom_Q1)\n",
    "\n",
    "            # Un-homogenize\n",
    "            uhom_Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            uhom_Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "\n",
    "            # Find the number of points there has positive z coordinate in both cameras\n",
    "            sum_of_pos_z_Q1 = sum(uhom_Q1[2, :] > 0)\n",
    "            sum_of_pos_z_Q2 = sum(uhom_Q2[2, :] > 0)\n",
    "\n",
    "            # Form point pairs and calculate the relative scale\n",
    "            relative_scale = np.mean(np.linalg.norm(uhom_Q1.T[:-1] - uhom_Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(uhom_Q2.T[:-1] - uhom_Q2.T[1:], axis=-1))\n",
    "            return sum_of_pos_z_Q1 + sum_of_pos_z_Q2, relative_scale\n",
    "\n",
    "        # Decompose the essential matrix\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        t = np.squeeze(t)\n",
    "\n",
    "        # Make a list of the different possible pairs\n",
    "        pairs = [[R1, t], [R1, -t], [R2, t], [R2, -t]]\n",
    "\n",
    "        # Check which solution there is the right one\n",
    "        z_sums = []\n",
    "        relative_scales = []\n",
    "        for R, t in pairs:\n",
    "            z_sum, scale = sum_z_cal_relative_scale(R, t)\n",
    "            z_sums.append(z_sum)\n",
    "            relative_scales.append(scale)\n",
    "\n",
    "        # Select the pair there has the most points with positive z coordinate\n",
    "        right_pair_idx = np.argmax(z_sums)\n",
    "        right_pair = pairs[right_pair_idx]\n",
    "        relative_scale = relative_scales[right_pair_idx]\n",
    "        R1, t = right_pair\n",
    "        t = t * relative_scale\n",
    "\n",
    "        return [R1, t]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaf605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 51/51 [00:23<00:00,  2.17pose/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"KITTI_sequence_2\"  # Try KITTI_sequence_2 too\n",
    "vo = VisualOdometry(data_dir)\n",
    "\n",
    "play_trip(vo.images)  # Comment out to not play the trip\n",
    "\n",
    "gt_path = []\n",
    "estimated_path = []\n",
    "for i, gt_pose in enumerate(tqdm(vo.gt_poses, unit=\"pose\")):\n",
    "    if i == 0:\n",
    "        cur_pose = gt_pose\n",
    "    else:\n",
    "        q1, q2 = vo.get_matches(i)\n",
    "        transf = vo.get_pose(q1, q2)\n",
    "        cur_pose = np.matmul(cur_pose, np.linalg.inv(transf))\n",
    "    gt_path.append((gt_pose[0, 3], gt_pose[2, 3]))\n",
    "    estimated_path.append((cur_pose[0, 3], cur_pose[2, 3]))\n",
    "plotting.visualize_paths(gt_path, estimated_path, \"Visual Odometry\", file_out=os.path.basename(data_dir) + \".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220e386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
